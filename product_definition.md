# Multi‚ÄëUser Personal Data Chatbot on Google Cloud : Product Definition

## Introduction  
Individuals today collect diverse personal datasets ‚Äì from chat messages and health metrics to location trails and music listening habits. Harnessing this data for insights can be daunting without technical skills. This document outlines a **multi-user SaaS chatbot application** that enables users to query their own data in natural language. The proposed solution combines a secure, multi-tenant **Google Cloud Platform (GCP)** architecture with Large Language Models (LLMs) for intelligent query parsing and response generation. The chatbot will parse complex questions (e.g. distinguishing ‚Äúlast year‚Äù from ‚Äúin the last 12 months‚Äù), fetch and join data across a user‚Äôs datasets, and deliver coherent answers or visualisations. It uses Google‚Äôs latest Vertex AI LLMs for reasoning and summarising results, all while adapting to each user‚Äôs available data and respecting privacy. In the following sections, we present the technical architecture, key interaction flows with storyboard-style mockups, a detailed product definition (personas, use cases, features, security), a phased development roadmap, and example prompts with a ([How to use RAG in BigQuery to bolster LLMs | Google Cloud Blog](https://cloud.google.com/blog/products/data-analytics/how-to-use-rag-in-bigquery-to-bolster-llms#:~:text=1)) ([How to use RAG in BigQuery to bolster LLMs | Google Cloud Blog](https://cloud.google.com/blog/products/data-analytics/how-to-use-rag-in-bigquery-to-bolster-llms#:~:text=BigQuery%20simplifies%20RAG%20in%20a,parts%20of%20it%20in%20a))style and rigour echo *The Economist* and *The Guardian*, aiming to inform a technical product owner with precision and clarity.

## Technical Architecture (GCP Platform and Data)  
**Overview:** The chatbot is built with GCP-native services for scalability, security, and integration with advanced AI. It follows a **multi-tenant architecture**: all users share the application and infrastructure, but each user‚Äôs data is isolated. The system dynamically discovers which data each user has provided and formulates queries accordingly. **Figure 1** illustrates a high-level multi-tenant design, where application workloads and data storage are compartmentalised per customer for security. Each user (tenant) shares the overall platform but has segregated data and access controls, ensuring their personal information remains invisible to others. 

![Figure 1: High-level multi-tenant architecture on GCP. Each customer‚Äôs application instance uses separate data stores (BigQuery, storage, etc.), enforced by Cloud IAM and optionally KMS for encryption. Shared services are minimised, and service accounts (SAs) are distinct per tenant to limit blast radius.](https://github.com/user-attachments/assets/a5c4ddd8-2900-4427-b297-51ca32f6abed)

### Data Ingestion and Storage  
Users upload structured datasets (e.g. CSV files of workouts or JSON exports of message logs) via a web interface. Uploaded files are first stored in **Cloud Storage** (for staging and backup) and then loaded into **BigQuery** tables. BigQuery is a serverless data warehouse well-suited for moderate table sizes (hundreds to thousands of records) and can handle up to 100k rows per table with ease. Each user gets a dedicated BigQuery *dataset* (a namespace for tables) under the hood ‚Äì for example, *User123.Messages*, *User123.Fitness*, etc. This provides logical isolation; queries are always scoped to the user‚Äôs dataset. In a higher-security configuration, the application could even create a separate GCP project for each user‚Äôs data storage to achieve physical isolation by default. In either case, **access control** is enforced so that only the owning user (and the service operating on their behalf) can access their BigQuery tables. All data at rest is encrypted by GCP-managed keys, and for sensitive personal data, the system could use **Cloud KMS** with customer-managed keys for an extra layer of security.

Data schemas may vary slightly between users. For instance, one user‚Äôs cycling activity table might have columns `date, distance, route` while another‚Äôs has `timestamp, distance_km, duration`. Rather than hard-coding column names, the system inspects the schema of each dataset upon upload and stores metadata (field types, known synonyms, etc.). A small **metadata registry** (in BigQuery or Firestore) maps broad data categories to user-specific schema details. This allows the query planner to interpret a question like ‚ÄúHow far did I cycle last week?‚Äù for any user by knowing which table and columns contain the cycling distance and timestamps for that user.

The architecture also includes an **optional semantic data store** for unstructured or textual data. For example, if users upload message histories or journal entries, the system generates vector embeddings for text fields and stores them for semantic search. Unstructured text entries (like message content) are converted into high-dimensional vectors using a text embedding model (via BigQuery ML or Vertex AI). BigQuery‚Äôs newer capabilities support storing and indexing vector embeddings directly, enabling similarity search within the warehouse. This means the chatbot can find relevant text snippets (e.g. a particular conversation) by semantic similarity, not just exact keywords. The **vector index** can be created in BigQuery for efficient retrieval, or a managed vector DB (such as Vertex AI Matching Engine or an open-source service) can be used if preferred. Consolidating structured data and embeddings in BigQuery simplifies governance by keeping all data queries in one platform, so the same access rules apply uniformly.

### Query Processing and LLM Orchestration  
At query time, the system leverages an orchestrator component (running on **Cloud Run** or **Google Kubernetes Engine**) that coordinates between the user interface, BigQuery, and the LLM. When a user asks a question in natural language, the following steps occur:

1. **NLU Parsing & Intent Recognition:** The user‚Äôs query is passed to an LLM (or a lightweight NLP parser) to interpret intent, entities, and temporal context. The LLM (such as Google‚Äôs PaLM 2 or Gemini model on Vertex AI) examines phrasing to infer what data is needed. For example, ‚ÄúHow many messages did I send last year?‚Äù indicates the *Messages* dataset, a count metric, and a time filter for the previous calendar year. The parser also normalises relative dates (‚Äúlast year‚Äù vs ‚Äúin the last year‚Äù) into explicit date ranges. If parts of the question are ambiguous (‚Äútop songs‚Ä¶ over what time period?‚Äù), the system may respond with a clarifying question to the user. This step uses a **Vertex AI** language model with a custom prompt that includes the user‚Äôs available data types and example interpretations. By using an LLM for this stage, the system can leverage its understanding of context and phrasing to map questions to data operations, much like natural language SQL generation.  

2. **Query Planning:** Based on the parsed intent, the orchestrator formulates a plan to retrieve the answer. This often involves constructing one or more SQL queries to BigQuery. For simple questions referencing a single dataset, one query may suffice (e.g. sum up steps in the given period). For complex questions, the planner may need to join data from multiple tables or perform sequential queries. Example: ‚ÄúDuring my vacation in France, did I burn more calories on days I listened to upbeat music?‚Äù might require filtering the *Location* dataset for entries in France (to identify ‚Äúvacation‚Äù days), then filtering *Fitness* data for those days‚Äô calories burned, and also checking the *Music* listening dataset for song tempo on those days. The orchestrator would likely run a series of queries: one to tag dates with location = France, another to aggregate fitness metrics on those dates, perhaps joining with a subquery or interim table of music tempo classifications. The query planner uses the metadata registry to adapt to each user‚Äôs schema, inserting the correct table and field names into the SQL. Complex query planning logic can be implemented with frameworks like **LangChain** agents or a custom planner. (Notably, LangChain‚Äôs SQL agent toolkit can connect an LLM to a database ‚Äì in this case BigQuery via a SQLAlchemy driver ‚Äì allowing the LLM to draft SQL statements autonomously. This approach was demonstrated by Harshad in using Vertex AI to interpret natural language and query BigQuery.)

3. **Data Retrieval:** The system executes the planned SQL queries on BigQuery. Thanks to BigQuery‚Äôs scalability, even multi-GB datasets can be processed in seconds, though here we deal with smaller personal datasets (under 100k rows). Query results are returned to the backend. If a semantic search was needed (for example, the question asks ‚ÄúWhat did I say about project X in my chats last month?‚Äù), the orchestrator uses the vector index: it converts the query or key phrases into an embedding and finds the nearest text entries (e.g. chat messages) via BigQuery‚Äôs vector search or an API call to the vector store. The relevant text snippets are retrieved alongside any structured data results. 

4. **LLM Answer Composition:** With the raw data (numbers, records, text excerpts) fetched, the system invokes the LLM again to compose a user-friendly answer. This step is performed by a **Vertex AI Generative model** (for instance, a PaLM 2 text-generation model or the newer Gemini model). The prompt to the LLM includes a concise summary of the question, the relevant data results, and instructions to formulate a helpful answer. If multiple partial results were obtained, the LLM can reason over them to produce insights ‚Äì e.g. comparing metrics across two periods, or summarising a set of records. The use of **retrieval-augmented generation (RAG)** ensures that the LLM‚Äôs answer is grounded in the user‚Äôs actual data. The model effectively acts as an analyst, explaining or summarising what the data shows. For example, it might reply: ‚ÄúYou sent **1,240 messages** in 2024, about 200 more than in 2023. The busiest month was June 2024.‚Äù The LLM is instructed to cite the data when appropriate and avoid fabricating information beyond what was retrieved. If the data is insufficient to answer (e.g. the user asks about a type of data they haven‚Äôt uploaded), the system responds gracefully, possibly with an apology or suggestion to provide that data. It is crucial that the chatbot **does not hallucinate** nonexistent data. In fact, a similar personal chatbot project explicitly chose to say it cannot answer a question if the data isn‚Äôt available, to reduce misinformation. Our system will follow this principle: answers are either derived from user data or clearly state if something cannot be determined.

5. **Response Delivery:** Finally, the composed answer (text, and possibly charts or tables) is sent back to the front-end chat interface for the user to view. The architecture ensures minimal latency by parallelising where possible ‚Äì for instance, the query planning LLM call might predict multiple SQL queries at once, or the system might stream partial LLM answers. BigQuery‚Äôs fast query execution and Vertex AI‚Äôs hosted models (which are optimised for low-latency inference) support responsive interactions. The chat UI updates with the answer and may allow the user to ask a follow-up. Throughout the exchange, the conversation context (prior Q&A pairs) is maintained in short-term memory (in the backend or cached in the client) so that follow-up questions can be understood in context. For multi-turn dialogue, the orchestration includes a rolling conversation state: recent questions and answers are included in the prompt for step 1 and step 4 as needed, enabling the LLM to resolve references like ‚Äúshe‚Äù or ‚Äúthat week‚Äù based on earlier discussion.

### Scalability, Multitenancy, and Security Considerations  
The solution is designed for multi-tenant use from day one. This means all components enforce **data isolation** and user-specific context. BigQuery natively supports row-level security and dataset-level permissions, so each query executed includes the user‚Äôs credentials or a service account scoped to that user‚Äôs data. In practice, the backend service uses a *service account* with access to all user datasets, but it only queries the dataset corresponding to the active user‚Äôs ID. Alternatively, the system could employ **per-tenant service accounts** (as shown in Figure 1‚Äôs Cloud IAM layer), where each user is assigned a dedicated service identity that has access only to their data stores. This adds an extra safeguard: even if the application logic errs, the underlying credentials wouldn‚Äôt allow cross-tenant data access. Each approach aligns with the principle that *each tenant‚Äôs data is isolated and remains invisible to other tenants*. 

Scalability is addressed at multiple layers. **Cloud Run** can autoscale the stateless query orchestrator to handle concurrent users. **BigQuery** effortlessly scales with data volume and query load; given our moderate per-user data sizes, we are well within BigQuery‚Äôs comfort zone. The LLM calls to Vertex AI are the most expensive in terms of compute. Vertex AI endpoints scale based on traffic, and we can configure model size per request or use smaller models for lightweight tasks (like initial parsing) and larger models for final answer composition. For cost and performance optimisation, the system might cache frequent query results or schedule periodic computations (for example, pre-aggregating some statistics daily). However, due to personal data‚Äôs often real-time nature (e.g. yesterday‚Äôs steps count), caching is mostly useful for static analyses or expensive vector search results.

**Extensibility:** The architecture is data-agnostic ‚Äì it does not hardcode any particular dataset schema or question type. New data connectors can be added for users to import additional types of information (for instance, integrating directly with Fitbit‚Äôs API to pull fitness data, or Google Takeout for location history). The core remains the same: store structured data in BigQuery (possibly with minor transformation), update the metadata registry with the new schema, and the LLM-based planner can immediately leverage it. The LLM‚Äôs broad knowledge of domains means it can handle unusual dataset questions as long as it has the schema and content. For example, if a user uploads a dataset of **reading history** (book titles with dates read and ratings), the system could handle questions like ‚ÄúHow many pages did I read last month?‚Äù by identifying a ‚Äúbooks‚Äù table and summing a ‚Äúpages‚Äù field ‚Äì assuming the metadata tells it such a field exists. We would test and refine the prompt engineering to ensure the LLM knows how to use new fields. Because Vertex AI continually improves and can be custom-prompted or fine-tuned, the system‚Äôs NLP capability will only get better at handling novel scenarios over time.

**Security & Privacy:** Personal data is highly sensitive, so the platform employs stringent security measures (detailed in a later section). In summary, all client connections are over HTTPS, user authentication is required (e.g. OAuth 2.0 login), and the backend strictly checks user identity on every request. Data in BigQuery is encrypted at rest by default, and access is audited. We also ensure that queries to the LLM do not inadvertently expose personal identifiers beyond what is necessary for context. Vertex AI, being a Google service, does not use customer-provided data to train its models unless explicitly enabled, so users‚Äô private data remains private. Compliance considerations (GDPR, etc.) are taken into account: users can delete their data, and the system will purge it from storage (with BigQuery and Cloud Storage deletion, and any derived vector indices). Logging is careful not to record raw personal data; only system events and perhaps anonymised metrics are logged for monitoring.

In summary, the technical architecture marries **GCP‚Äôs data prowess** (BigQuery for structured and vector data) with **LLM intelligence** (Vertex AI) to create a flexible, robust personal data chatbot. It is built to be **multi-tenant and secure by design**, capable of scaling to many users while keeping each user‚Äôs digital life separate and safe. Next, we illustrate how users interact with the chatbot through key product flows and mockups.

## Key Interaction Flows & Chatbot Mockups  
To clarify the user experience, this section walks through key interactions with the system, accompanied by storyboard-style descriptions. The focus is on how a typical user would upload data and query it via the chatbot. Each flow highlights the dynamic between the user and the application (what the user sees or does, and how the system responds).

### 1. Onboarding and Data Ingestion Flow  
**Scenario:** A new user signs up and uploads their first dataset.  
1. **User Registration:** The user visits the SaaS application‚Äôs web portal and signs in (using a secure login, e.g. Google OAuth or email 2FA). They land on a welcome dashboard that explains how to add data for the chatbot to use.  
2. **Dataset Upload:** The user clicks ‚ÄúAdd Data‚Äù and is presented with options to upload files or connect to services. In our example, the user chooses to upload a CSV of their past year‚Äôs fitness activities. A mockup of this interface shows a file picker and a form to describe the dataset (dataset name, type/category selection, etc.). The user names it ‚ÄúCycling Workouts 2024‚Äù and selects the category ‚ÄúFitness ‚Äì Cycling‚Äù. They then upload the file.  
3. **Schema Detection:** The system processes the file: it detects columns like *date, distance, duration, calories*. The user is shown a preview: ‚ÄúWe found 4 columns: Date, Distance (km), Duration (min), Calories‚Äù. The interface might ask for confirmation or data type adjustments (e.g. ensure Date is recognised as date). In this storyboard, the user confirms the schema looks correct.  
4. **Storage Confirmation:** The data is then sent to BigQuery (behind the scenes). After a brief processing time, the UI notifies the user that the dataset has been successfully added. The user now sees ‚ÄúCycling Workouts 2024‚Äù listed in their Data Sources list on the dashboard. There is a small indicator that the data is **indexed and ready** for queries. (If this were a large text dataset, here we would also show progress of embedding creation, but for numeric data it‚Äôs instant.)  
5. **Continuous Update Option:** The interface also offers the user options to update this dataset later ‚Äì e.g. upload a new file to overwrite, or schedule periodic appends. In our case, the user decides to later add their 2023 cycling data as well, which they can do by the same process, resulting in another table.

![Mockup Illustration:* *Frame 1:* A dashboard screen showing ‚ÄúNo data added yet. Get started by uploading your personal data.‚Äù *Frame 2:* The file upload modal with fields for dataset name and category. *Frame 3:* A confirmation message: ‚Äú‚úÖ Cycling Workouts 2024 uploaded. 1,045 records added.‚Äù The data source list now contains an entry for this dataset.](https://github.com/user-attachments/assets/0f8ecc47-ed87-40c7-8a33-077663936448)

### 2. Asking a Simple Question (Single Dataset Query)  
**Scenario:** The user asks the chatbot a straightforward question about one of their datasets.  
1. **User‚Äôs Question:** The user navigates to the **Chatbot** section of the app. They are greeted by the chatbot interface ‚Äì a text input box and a chat history pane. They type: *‚ÄúHow many kilometres did I cycle in total last year?‚Äù* and hit send.  
2. **Chatbot Understanding:** The chatbot (powered by the backend LLM and planner) identifies that ‚Äúcycle‚Äù and ‚Äúkilometres‚Äù likely relate to the **Cycling Workouts** dataset. It also interprets ‚Äúlast year‚Äù as the year 2024 (assuming current date is in 2025).  
3. **System‚Äôs Data Retrieval:** Without further ado, the system runs a query on the user‚Äôs *Cycling Workouts 2024* table, summing the distance column for the date range 2024-01-01 to 2024-12-31. It gets a result, say **3,560 km**.  
4. **Chatbot‚Äôs Answer:** The chatbot responds in the chat: *‚ÄúYou cycled **3,560 kilometres** in total during 2024.‚Äù* The answer appears within a few seconds of the user‚Äôs question. It is phrased in a friendly, factual tone. The interface might style the number in bold for clarity. If the user had a *Cycling Workouts 2023* dataset as well, the bot might even add: *‚ÄúFor comparison, in 2023 you logged 3,421 kilometres.‚Äù* (The chatbot is capable of slight embellishments like comparisons if relevant data is present, even if the user didn‚Äôt explicitly ask ‚Äì though this is configurable to avoid overwhelming the user.)  
5. **User Acknowledgment:** The user sees the answer and is satisfied. They did not need to specify the dataset or dates explicitly ‚Äì the system figured it out. The user might follow up with another question or just keep the information in mind. They now trust that they can ask more complex queries.

*Mockup Illustration:* A chat window screenshot: On the left, the user‚Äôs avatar next to their query: ‚Äú**User:** How many kilometres did I cycle in total last year?‚Äù. Below it on the right, the chatbot avatar and answer: ‚Äú**Chatbot:** You cycled **3,560 km** in total during 2024.‚Äù This simple Q&A demonstrates an MVP-level capability. The style is akin to messaging apps ‚Äì clear distinction between user and bot messages, and the bot message perhaps with a small icon indicating it came from the ‚ÄúPersonal Analyst Bot‚Äù. 

### 3. Clarification Dialogue (Ambiguity Resolution)  
**Scenario:** The user asks a question that is ambiguous or too broad, and the chatbot engages to clarify.  
1. **User‚Äôs Question:** The user now asks: *‚ÄúWhat about last year?‚Äù* as a follow-up, without additional context. Since this question is vague on its own, the chatbot needs context from the prior conversation. The previous query was about cycling distance, so ‚Äúwhat about last year?‚Äù could mean the user wants to know the previous year‚Äôs total (2023) or some other comparison. However, the bot already pre-emptively mentioned 2023 in the last answer. To be sure, or consider a different context, the bot will clarify.  
2. **Chatbot Clarifies:** The chatbot responds: *‚ÄúDo you mean how far you cycled in the year before (2023)?‚Äù* It chooses this interpretation because that‚Äôs the most logical follow-up given the context. (If multiple datasets were in play, it might ask which data or which metric the user is referring to.)  
3. **User Confirms:** The user replies, *‚ÄúYes, compare 2024 to 2023.‚Äù* Now the intent is clear ‚Äì the user wants a comparison between years.  
4. **System‚Äôs Data Retrieval:** The system runs a query (or two) to get total cycling km for 2023 (from the other table) as well as 2024 (which it already has, possibly cached from earlier).  
5. **Chatbot‚Äôs Answer:** The chatbot now provides a comparative answer: *‚ÄúIn 2024 you cycled **3,560 km**, whereas in 2023 you cycled **3,421 km**. That‚Äôs an increase of about 4%.‚Äù* It might also present this in a more visual form if available ‚Äì for example, a small bar chart icon could be offered that, when clicked, shows a bar chart of 2023 vs 2024 distance. (Such a feature might come in a later version, not MVP.)  
6. **User Feedback:** The user appreciates the clarification step ensuring they were asking the intended question. This dialogue demonstrates the chatbot‚Äôs ability to handle pronouns and time references in follow-ups by leveraging conversation history.

*Storyboard Note:* This flow would be depicted as a short back-and-forth exchange in the chat interface. It highlights the chatbot‚Äôs polite clarifying question and the maintenance of context between turns. The design principle is to never leave the user with an unanswered or wrongly answered question when a simple clarification can resolve ambiguity.

### 4. Complex Query (Joining Multiple Datasets)  
**Scenario:** The user asks a more complex question that involves correlating two different datasets.  
1. **User‚Äôs Question:** Now the user asks: *‚ÄúDid I tend to run longer distances on days when I slept better?‚Äù* This question involves two distinct datasets: perhaps a *Running Activities* dataset (distance per run, date) and a *Sleep* dataset (hours of sleep per night, date). The user has uploaded both: one from a fitness app and one from a sleep tracking app.  
2. **Chatbot Analysis:** The LLM parses this and identifies two data needs: running performance and sleep quality, and that it‚Äôs asking for a correlation or comparison (‚Äúon days when I slept better‚Äù suggests filtering by sleep data). It realises it should look at days as the common key. It checks that the user indeed has those datasets available (if not, it would say it lacks the data). In this case, both exist. ‚ÄúSlept better‚Äù likely implies above-average sleep or some threshold; the bot might interpret it as the top quartile of sleep hours or when sleep > X hours. It decides on a strategy: find the average running distance on *good sleep* days vs *bad sleep* days.  
3. **System‚Äôs Data Retrieval:** The orchestrator executes a join in BigQuery: joining the Running table and Sleep table on date. It then computes, for example, the user‚Äôs median or average run distance on days with >=8 hours of sleep vs <8 hours of sleep (assuming 8h as a threshold for ‚Äúgood sleep‚Äù). The results might show: on good sleep days, average run = 8.5 km; on poor sleep days, average run = 6.7 km.  
4. **Chatbot‚Äôs Answer:** The chatbot responds with an insightful answer: *‚ÄúIt appears so. On nights when you slept 8+ hours, your runs next day averaged about 8.5 km. On shorter-sleep nights, they averaged 6.7 km. In general, better sleep aligned with longer runs.‚Äù* The answer merges data from both sources and delivers a conclusion. It may couch the conclusion carefully (since correlation is not causation, a thoughtful tone like *‚ÄúThis suggests a correlation: you ran further on well-rested days.‚Äù*). The style is analytical yet accessible, much like *The Economist* explaining a personal trend with data.  
5. **User Reaction:** The user finds this multi-dataset answer very powerful ‚Äì it‚Äôs the kind of insight that traditionally would require manual data wrangling. They might follow up with ‚ÄúWhat about pace?‚Äù or some related question, and the cycle continues.

*Mockup Illustration:* This could be shown with a combined data chart or at least the textual answer clearly referencing both sleep and run data. Perhaps an icon or tag on the answer indicates that it used multiple datasets. For example, little icons or labels ‚ÄúRunüèÉ + Sleepüí§‚Äù could appear next to the answer to transparently show which data sources were used (this is a possible UI enhancement to build user trust in where the answer comes from).

### 5. Handling Missing Data Gracefully  
**Scenario:** The user asks something for which data is not available.  
1. **User‚Äôs Question:** Suppose the user asks: *‚ÄúHow many calories did I consume last week?‚Äù* However, the user has not uploaded any diet or calorie tracking data to the system.  
2. **Chatbot Response:** The chatbot‚Äôs planner searches the metadata of available datasets and finds nothing related to nutrition or calorie intake (as opposed to calories burned, which might be in fitness data but the wording ‚Äúconsume‚Äù indicates food). Recognising this, the chatbot responds apologetically and helpfully: *‚ÄúI‚Äôm sorry, I don‚Äôt have your dietary data to answer that. If you track your meals or calories, you can upload that data and I‚Äôll be able to assist.‚Äù* It may guide the user to add such a dataset by providing a direct link or instructions.  
3. **User Outcome:** The user now knows the limitation. Maybe they indeed have a food log CSV somewhere ‚Äì they proceed to upload it. Once uploaded, the user can re-ask the question and now get an answer. The chatbot‚Äôs graceful handling of missing data ensures it doesn‚Äôt try to guess or provide a wrong answer. This maintains trust; as noted in other RAG-based chatbots, explicitly saying ‚Äúcannot answer‚Äù when data is lacking helps reduce misinformation.  
4. **System Adaptation:** Internally, when the user adds the new dataset (say a calorie log), the system will include it in future query planning. The next time the question is asked, the chatbot might combine the calorie data with activity data (if relevant) or answer directly from the new dataset.

### 6. Ongoing Updates and Continuous Learning  
**Scenario:** The user continues to use the chatbot over time and adds more data; the system improves in understanding the user.  
- Over weeks, the user might add monthly updates to their datasets (the architecture supports appending new records, which are immediately available for querying). The chatbot could proactively acknowledge new data, e.g., *‚ÄúI see you‚Äôve added your August fitness data. You can ask me about your summer fitness summary now.‚Äù* (Such proactive tips would be a later feature to engage users.)  
- The chatbot also refines its prompts or employs fine-tuning as it gathers more interactions. For instance, if the user often asks about ‚Äúlast month‚Äù vs ‚Äúthis month‚Äù, the system might start offering a default comparison in answers.  
- Throughout, the interface remains the chat window as the primary mode of interaction, possibly supplemented by a side panel showing what data sources are currently in use or when they were last updated.

These interaction flows demonstrate the user-centric design of the chatbot. The **storyboards** highlight intuitive conversations: uploading data, asking questions freely, and receiving insightful, context-aware answers. In all cases, the complexity (data joins, disambiguation, query logic) is handled behind the scenes by the architecture described earlier. Next, we formalise the product definition, including user personas, key use cases, features, and the security model, to solidify the requirements and scope.

## Product Definition and Scope  

### User Personas and Use Cases  
We envision several archetypal users (personas) for this personal data chatbot, each with distinct goals. These personas inform the features and priorities of the product:

- **The Quantified Self Enthusiast (Adam):** Adam is a tech-savvy individual who tracks everything ‚Äì fitness, sleep, diet, location, and more. He wants a single interface to query *all* his personal stats and find patterns. Use cases: *‚ÄúCompare my average sleep on weekdays vs weekends,‚Äù ‚ÄúWhich month did I walk the most steps?‚Äù* Adam values depth of analysis and will use advanced features like multi-dataset queries and visualisations. He pushes the system‚Äôs ability to handle lots of data types together.

- **The Fitness Fanatic (Bella):** Bella mostly cares about her workout data (runs, cycles, gym sessions) and health metrics (heart rate, calories burned). She uses devices and apps that export data which she uploads regularly. Use cases: *‚ÄúHow has my running pace improved over the last 6 months?‚Äù, ‚ÄúDid I burn more calories on days I do strength training or cardio?‚Äù* She may not be extremely technical, so she relies on natural language questions. Consistency and accuracy of answers are key for her, as she might base training decisions on them.

- **The Busy Professional (Charlie):** Charlie is interested in productivity and communication patterns. He uploads his work calendar data, chat logs (e.g. Slack or email metadata), and perhaps time-tracking data. Use cases: *‚ÄúHow many meetings did I have last quarter compared to the previous one?‚Äù, ‚ÄúWho are the top five people I emailed most this month?‚Äù* Charlie uses the chatbot to reflect on how he spends his time and with whom. He values quick, factual answers and might export some results to share or present at work (e.g. how his client contacts grew).

- **The Music Aficionado (Dana):** Dana connects her Spotify listening history and perhaps mood journal entries. She‚Äôs curious about how her music listening correlates with mood or activity. Use cases: *‚ÄúWhat genre did I listen to most during my workouts?‚Äù, ‚ÄúWas I happier on days when I listened to jazz?‚Äù* Dana‚Äôs use pushes the system into combining media history with either fitness or journal data, requiring both structured and unstructured analysis (e.g. sentiment from journal text). She values the novelty of questions that haven‚Äôt been pre-baked in any app.

- **The Privacy-Conscious User (Evelyn):** Evelyn is generally like one of the above personas but is extremely cautious about her data. She will scrutinise the security model and needs assurance that her information is safe. Use case: She might test the system with smaller or obfuscated data first, and ask meta-questions like ‚ÄúHow do you protect my data?‚Äù (which the chatbot could answer from a help documentation dataset). Evelyn‚Äôs concerns drive the emphasis on transparency and trust in features.

These personas highlight broad categories: **health and fitness tracking, personal productivity, media consumption, social interactions**, and an overall **data nerd**. The product‚Äôs feature set must be flexible to accommodate all, without assuming everyone will use every feature.

### Key Features and Functional Scope  
From the personas and problem statement, we define the core features of the chatbot application:

- **Natural Language Question Answering:** At its heart, the chatbot allows users to ask questions in everyday language about their data. This includes:
  - Temporal queries: understanding phrases like ‚Äúlast year‚Äù, ‚Äúthe past week‚Äù, ‚Äúbetween March and June‚Äù, and translating them to date filters accurately.
  - Comparative queries: e.g. ‚Äúcompare A and B‚Äù or ‚Äúwhich is higher, X or Y?‚Äù leading to multi-part answers or even simple charts.
  - Aggregation and summary: answering ‚Äúhow many/much‚Äù, ‚Äúaverage of‚Ä¶‚Äù, ‚Äúmaximum/minimum‚Äù etc., by translating to the appropriate SQL aggregations.
  - Detail queries: e.g. ‚Äúlist all events where‚Ä¶‚Äù ‚Äì the chatbot can also retrieve records or examples (though returning very large lists is discouraged; the bot might summarise or show top N items by default).

- **Multi-Dataset Reasoning:** The ability to draw insights from multiple datasets at once. This includes joining on common keys (like date, location) or even without explicit keys (using time overlap or semantic similarity). For example, combining heart rate and music tempo requires aligning by timestamp; the system handles such logic if the question implies it. This feature turns the chatbot into a personal data analyst that can find relationships (correlations, sequences) across different facets of one‚Äôs life.

- **Contextual Conversation & Follow-ups:** Users can have a conversation with the bot. It remembers context within a session, so users can ask follow-up questions without restating all parameters. The bot can resolve pronouns or ellipsis (e.g. ‚Äúand what about July?‚Äù following an earlier query about June). We scope this to session-based context (when the user returns later or after a long gap, the context might reset for privacy and simplicity, unless we choose to implement long-term memory explicitly). This feature requires careful handling to avoid confusion, and the bot will re-clarify if a follow-up is ambiguous out of context.

- **Clarification and Guidance:** The chatbot will actively ask clarifying questions if it‚Äôs unsure what the user means. Rather than guess and risk a wrong answer, it uses a cooperative approach: *‚ÄúI have data on both running and cycling; which one did you want to ask about?‚Äù* or *‚ÄúBy ‚Äòbest‚Äô, do you mean highest value or something else?‚Äù* This interactive disambiguation is a feature that ensures accuracy and user satisfaction. It essentially implements a dialog management atop the raw LLM responses.

- **Data Source Management:** A user-friendly interface for managing personal datasets:
  - Uploading new datasets (through UI or potentially via API integrations for advanced users).
  - Viewing what data is uploaded: a list of datasets with metadata like last updated, number of records, and recognized fields.
  - Updating or deleting datasets: e.g. remove a dataset or replace it if needed.
  - Perhaps basic preview or stats (like a small summary: ‚ÄúCycling: 1,045 entries from Jan‚ÄìDec 2024‚Äù).
  - Tagging/categorising datasets so the system knows what kind of data it is (the user might help by selecting a category on upload as we saw).

- **Extensibility for Data Schema:** The system should handle slightly varying schemas by configuration rather than code. This means features like a *schema mapping assistant* during upload could be included: if a user‚Äôs file columns don‚Äôt match known patterns, allow them to specify what each column represents (e.g. ask ‚ÄúWhich column is the timestamp?‚Äù if not obvious). This way the user actively teaches the system, which stores that mapping. This feature ensures broad compatibility with whatever data the user has, as long as it‚Äôs structured.

- **Result Presentation:** While text answer is the primary mode (and required for MVP), the product should eventually support rich answers:
  - **Visualisations:** If a user asks for something trend-like or comparative, the bot can generate a simple line chart, bar chart, or pie chart as appropriate. Initially, it might just provide textual descriptions (‚Äúin a chart, you‚Äôd see X rising‚Äù), but an advanced feature would be an auto-generated chart image. GCP‚Äôs ecosystem or libraries (like Matplotlib, Altair, or Google Charts via an API) could be used to create charts on the fly. For GA, we envision the chatbot can show, for instance, a line graph of step count over the week when asked ‚ÄúShow me a graph of my steps this week‚Äù.
  - **Tables or Lists:** For queries like ‚ÄúList all days I exceeded 10,000 steps,‚Äù the bot might present a brief table of dates and step counts, or a bulleted list in the chat. There will be sensible limits (e.g. show top 5 results and then offer ‚Äúand 12 more‚Ä¶ export?‚Äù).
  - The style of presentation will follow a clean, minimalist aesthetic (in line with *The Economist* style ‚Äì informative but not flashy). 

- **Personalisation and Learning:** Over time, the chatbot could personalise its behavior:
  - Remember user preferences (if a user always prefers distance in miles instead of km, the bot could learn that).
  - Allow the user to set certain defaults (preferred units, or linking datasets ‚Äì e.g. mark certain datasets as ‚Äúvacation periods‚Äù to be used when that concept is invoked).
  - Possibly allow custom aliases for datasets (if user says ‚Äúmy Garmin data‚Äù it knows which dataset that refers to).

- **Security & Privacy Features:** (Detailed later, but as part of product scope, features include account security, data encryption, compliance options like data export and deletion by user command, etc.) For example, an **Account Settings** page lets the user download all their data or permanently delete their account and data (to comply with right-to-erasure laws).

- **Help and Onboarding:** Built-in guidance such as example questions, tutorials on how to phrase queries, and perhaps a ‚Äúrecipe book‚Äù of interesting questions for each data type. This is a softer feature but important for user adoption ‚Äì some may not immediately know what to ask. We might provide templates like ‚ÄúTry asking: ‚ÄòHow did my average heart rate change last month?‚Äô‚Äù.

The **feature scope** will be phased (not everything in MVP). The MVP focuses on core Q&A and data upload; visualisations and heavy personalisation come later, for example. Importantly, the chatbot will *not* do a few things: it won‚Äôt allow querying other users‚Äô data (no social features in v1, to avoid privacy issues), it‚Äôs not a general web search or knowledge chatbot about the world (it specifically answers about the user‚Äôs data, though it has general knowledge to interpret questions), and it‚Äôs not initially providing real-time alerts or push notifications (it‚Äôs user-driven Q&A, though that could be a future direction ‚Äì e.g. ‚Äútell me each week how I did‚Äù).

### Constraints and Assumptions  
In developing this product, we recognise certain constraints and make assumptions:

- **Data Volume:** Each user‚Äôs data is assumed to be moderate in size (1K to 100K rows per dataset, a few megabytes to tens of MBs). The architecture is capable of more, but our design and costs assume personal-scale data, not enterprise-scale. If a user tries to upload millions of rows (say their entire tweet history), BigQuery can handle it, but UI and query performance might degrade without adjustments. We assume typical users have on the order of dozens of datasets, not hundreds.

- **Data Schema Consistency:** We assume that within a broad category (e.g. workouts, messages, location logs), most users‚Äô data will share common traits (dates, identifiers, metrics). The system is designed to handle variations, but if a dataset is completely unstructured or very unusual, the LLM might need additional hints. We assume users will use the guidance provided to map their data correctly. Edge cases where data is very sparse or oddly formatted might require them to preprocess it (we won‚Äôt initially attempt to magically clean or reshape badly structured data).

- **Real-Time Updates:** The system isn‚Äôt initially intended for streaming real-time data or continuous queries. It assumes data is ingested in batches (like daily or ad-hoc uploads). Questions about ‚Äútoday so far‚Äù are answerable if the user just uploaded today‚Äôs data or if we integrate with an API to fetch the latest. But the MVP will not include streaming ingestion (that could be in a later phase with something like Pub/Sub feeding BigQuery). So a constraint is that data might be as fresh as the last upload; we will communicate to users if their data is old or if a query‚Äôs time range goes beyond what‚Äôs available.

- **LLM Limitations:** The reliance on LLMs means occasional errors in understanding or responding. We mitigate this with system prompts and few-shot examples to improve reliability. However, we assume the chosen Vertex AI model is sufficiently advanced (by 2025, models like Gemini are state-of-the-art) to handle most queries well. There is a constraint of **cost and latency**: calling a large LLM for every single message can be expensive and slow. To manage this, we might use a smaller model or heuristic for initial parsing and only use the big model for final answer composition. We assume a budget that allows each user to make a reasonable number of queries per month without exorbitant cost (perhaps using caching and efficient query techniques to minimise LLM token usage). The design must be mindful of this constraint, using BigQuery to do heavy lifting (since SQL operations are cheaper than large LLM context lengths, for example).

- **Privacy and Trust:** We assume users will only join if they trust the platform. Thus we have a near-zero tolerance for data leaks or cross-user access. We also expect users to provide truthful data (the system isn‚Äôt validating the accuracy of what they upload, it just uses it). If a user uploads nonsense, the answers will be nonsense relative to that data; that is acceptable since it‚Äôs their own data. We focus on not outputting anything beyond the data scope. Another assumption: users are okay with their data being processed by Google Cloud services (this should be clear in terms ‚Äì e.g. that their data will reside in BigQuery on GCP). Highly sensitive users might ask for on-prem or self-hosted versions, but that‚Äôs out of scope for now (our SaaS offering is in the cloud).

- **Multi-tenancy Implementation:** We choose a particular multi-tenant approach (logical isolation in BigQuery with user-specific identifiers). The assumption is that this will be sufficient for our user base and simpler to manage than thousands of projects. If we were to sign up enterprise clients or have stricter isolation needs, we might revisit that. But for a SaaS for individuals, the overhead of separate projects per user is high, so we assume a single project with careful dataset isolation works (with guardrails in code and IAM). We will thoroughly test that one user cannot ever access another‚Äôs data via any path.

- **Compliance:** We assume from the start compliance with major regulations (GDPR for EU, CCPA for California, etc.) will be necessary once the product scales. As such, data export/delete and consent mechanisms are planned. We also note that since this is personal data provided by the user themselves, in many regimes the user giving their own data to a tool for their own use is less problematic than a company collecting user data unbeknownst to them. Nevertheless, our policies and features will align with privacy best practices.

### Security Model  
Security is a first-class concern in this application, given the personal and potentially sensitive nature of user data. The security model spans authentication, authorisation, data handling, and platform security:

- **Authentication:** All users must authenticate to access the service. Likely we will implement OAuth 2.0 login with trusted providers (Google, etc.) or our own email/password with multi-factor. Sessions will be securely managed (HTTP-only cookies or token-based auth to the frontend, and tokens passed to backend API calls). The chat interface and data management UI are only accessible after login. We will use **Cloud Identity Platform** or Firebase Auth for a robust and secure identity solution, unless we integrate with existing accounts.

- **Authorisation & Access Control:** After auth, every request on behalf of a user carries their identity context. The backend checks this against the target resources. For data queries, the mapping of user -> BigQuery dataset is strictly enforced. For example, if user 42 is logged in, the backend will only query tables in dataset `user42_*`. Even if a malicious user tried to craft a request for another dataset, the backend will validate the dataset belongs to them. Additionally, at the BigQuery level, we can implement **view-based access control** or separate service accounts: for instance, one approach is to have a Cloud Run instance per user with a specific service account, but that‚Äôs not scalable for many users. Instead, we rely on our application logic plus careful IAM: The service account used by the app has permissions to query all user datasets, but our code never allows cross-user queries. We will also implement monitoring/alerting for any anomalous access patterns in BigQuery (like if someone somehow tried to union all datasets). Data in Cloud Storage (uploads) similarly will be prefixed or segregated by user and only accessible via backend after auth.

- **Encryption and Data Protection:** As mentioned, all data at rest in BigQuery is encrypted by Google-managed encryption keys by default. We have the option to use **Customer-Managed Encryption Keys (CMEK)** for BigQuery and GCS if enterprise users require it. In transit, all communication uses TLS. Internally between services (Cloud Run to BigQuery etc.), it‚Äôs within Google‚Äôs network and/or also TLS protected. If we store any sensitive config (like API keys if users link external services), those are kept in **Secret Manager** and not in plain text.

- **LLM Data Handling:** When we send data to Vertex AI for the LLM to process, we also consider that a form of data handling. Vertex AI‚Äôs terms ensure that data is not used to train the model or shared, but we might still minimise sending raw personal identifiers. For example, if the data contains names of people the user messaged, and the user asks ‚ÄúWho emailed me the most?‚Äù, the answer requires a name. But we might instruct the LLM not to reveal names from the data unless explicitly asked, to avoid any accidental leakage beyond answering the question. All prompt assembly is done backend side, so the user doesn‚Äôt see raw data unless it‚Äôs part of the answer.

- **Audit and Logging:** Every query executed and data access can be logged (without logging the actual personal content). We will keep logs like ‚ÄúUser X ran query on dataset Y at time Z‚Äù and high-level metrics (e.g. count of records returned). This is useful for audit if something goes wrong and for the user‚Äôs own transparency (we could even show them their recent queries history, which is both a UX feature and a security feature). GCP‚Äôs Cloud Audit logs will also automatically record BigQuery job details and Cloud Storage access, which helps in any security review.

- **Multi-Tenant Testing:** We will extensively test with dummy users that there is no data bleed. For instance, create two users with similar questions and ensure each only gets answers from their dataset. We may also incorporate **fuzz testing** for the query planner to ensure a prompt from user A can never include content from user B because the planner logic simply has no knowledge of other users‚Äô data (each user‚Äôs metadata registry is separate or keyed by user).

- **Session and CSRF Protection:** In the web UI, normal web security practices apply. We will protect against cross-site request forgery by using proper tokens and not exposing unsafe endpoints. The API will not allow requests without auth. We‚Äôll also have rate limiting to prevent abuse (someone spamming thousands of queries, or denial-of-service attempts). Each user might be limited to a reasonable number of queries per minute ‚Äì this doubles as cost control.

- **Backups and Data Retention:** User data being valuable, we will backup datasets periodically (perhaps via scheduled BigQuery exports or using point-in-time recovery features). But we also allow users to truly delete data if they want, which means backups must eventually purge that data too (respecting retention policies). The user will be informed about how long a deleted dataset might linger in backups (perhaps 30 days) unless an immediate hard delete is requested.

- **Compliance and User Control:** The security model aligns with privacy laws: users can download their data (data portability) and delete it (right to delete). We will have a privacy policy clearly stating that the data is used only to provide answers to the user themselves, and not for any advertising or selling. Because this is a multi-tenant SaaS, we, the provider, do have access to the infrastructure ‚Äì but we will implement administrative access controls such that no staff can arbitrarily query user data without approval (and if support needs to help a user with an issue, it‚Äôs done in a controlled way with their permission). Possibly, we can even encrypt each user‚Äôs data with a key derived from their password (end-to-end style) for ultimate privacy, but that complicates the ability to use LLM on it. For now, we trust GCP‚Äôs robust internal security.

In short, the product is designed with a **zero-trust mindset**: assume no user data should be accessible unless explicitly authorised. GCP‚Äôs built-in security features (IAM, audit logs, encryption) provide a strong foundation, and we build on that with careful application-layer checks. 

Now that we have described what the product will do and how it will do it securely, we turn to the development roadmap. This will outline how we plan to build and roll out the product in phases, from a minimum viable product to a full general availability release.

## Development Roadmap (MVP to GA)  
Building this multi-faceted product will be an iterative journey. We propose a phased roadmap with clear milestones, ensuring that at each stage we deliver a working product, gather feedback, and then expand capabilities. The phases include a Minimum Viable Product (MVP), a Private Beta, and a General Availability (GA) launch, with potential intermediate milestones as needed.

### Phase 1: Minimum Viable Product (MVP)  
**Goal:** Deliver a functional core product to a small set of pilot users, focusing on the essential use case ‚Äì asking questions about one‚Äôs data and getting correct answers.  

**Scope of MVP Features:**  
- **Data Upload:** Allow users to upload at least one dataset (CSV). Keep the schema handling simple (perhaps require a template or provide a few presets for common data types like a sample ‚Äústeps.csv‚Äù format). 
- **Basic Q&A:** Support natural language questions on a single dataset. The MVP might handle one dataset at a time (the user may have to select which dataset they want to query, or the question must explicitly name it) to reduce ambiguity.
- **LLM Integration:** Use Vertex AI‚Äôs text model for parsing and answering, but in MVP we can start with simpler prompts and perhaps a smaller model (to keep cost down while testing). Possibly we restrict question complexity initially.
- **UI:** A basic web interface: login page, data upload page, and a simple chat interface. It need not be beautifully styled yet, but clear enough. No rich charts, just text answers. Possibly even a one-turn query interface (ask question -> get answer, not a full chat memory) to simplify.
- **Multi-Tenancy Baseline:** The architecture is set up for multi-tenancy (even if only a handful of users in pilot). Ensure isolation works. Possibly limit MVP to, say, 10 pilot users to monitor system behavior.
- **Security:** Basic auth, using a quick solution (e.g. Firebase Auth can accelerate this). Ensure each user‚Äôs data is separate as planned. For MVP, we might not implement user-managed encryption keys, but rely on GCP defaults.
- **No Complex Joins:** We might postpone multi-dataset queries. MVP will focus on questions answerable from single tables. This reduces complexity in query planning. If a user has multiple datasets, they can query them separately for now.
- **No Clarification Dialogues (Reactive only):** If a question is ambiguous, the MVP bot might either take a best guess or return a generic ‚ÄúI‚Äôm not sure how to answer that‚Äù rather than engage in multi-turn clarification. Interactive clarification can be planned but may not make the first cut.
- **Deployment:** Deploy on GCP (maybe all in one project). Use Cloud Run for backend, BigQuery for data. We keep manual oversight on the system. Possibly not worrying about full auto-scaling since user count is small, but the components inherently scale if needed.

**Timeline & Deliverables for MVP:** We estimate ~3 months for MVP development given a small agile team. Key deliverables:
- Basic UI/UX design (wireframes) and implementation.
- Back-end services: file upload handling, BigQuery integration, calling Vertex AI API.
- A set of **unit tests** for the query logic (e.g. given a known dataset and a question, does it produce the right SQL and answer).
- Internal demo with the pilot users‚Äô own data to gather feedback.
- Documentation for MVP: quickstart guide for users, and an architecture doc (maybe this document) for internal reference.

**Success Criteria for MVP:**  
   - Users can successfully upload a dataset and get at least 5-10 different questions answered correctly.
   - System correctly interprets basic time phrases (day, week, month names, last X).
   - No major... major errors in accuracy or security observed during the pilot. Users should report that the system answers questions correctly (at least for straightforward queries) and that they feel confident uploading their data.  

### Phase 2: Private Beta  
**Goal:** Expand capabilities and test with a broader audience (e.g. a closed beta with dozens of users). Incorporate feedback from MVP and add important features that were deferred.  

**Scope of Beta Enhancements:**  
- **Multiple Datasets & Joins:** Enable the chatbot to handle questions that involve more than one dataset. This includes implementing the more advanced query planner and testing common multi-source queries (like correlating sleep and exercise). The LLM prompts are refined to manage this complexity.  
- **Clarification Dialogues:** Introduce the interactive clarification feature. The bot will now ask follow-up questions when needed, rather than giving up or guessing. This requires building a simple dialogue manager to track pending clarifications.  
- **Semantic Search Integration:** If users have textual data (messages, notes), implement the vector embedding and similarity search pipeline. Likely using BigQuery‚Äôs ML capabilities to generate embeddings and search within them. Beta users can then ask questions like ‚ÄúWhen did I mention project X in my chats?‚Äù and get relevant snippets.  
- **UI Improvements:** Refine the chat UI with quality-of-life features: loading spinners while the bot thinks, the ability to scroll through past Q&A, perhaps a button to copy an answer or export data. Add a basic **visualisation** component ‚Äì maybe start with static charts for a couple of query types (like time series line chart for trend questions). The UI should also present the list of data sources more clearly and allow switching context if needed (e.g. a dropdown to focus the bot on a particular dataset, if that makes interaction easier).  
- **Data Management:** Beta might introduce integration connectors (for example, import from Google Fit or Strava via API, not just file upload). Even if limited, demonstrating one live integration will set the stage for future extensibility.  
- **Security & Privacy:** By beta, implement full user account controls: password resets, email verification, etc., and allow users to delete datasets on their own. Conduct a security audit or pentest with a small group to ensure no vulnerabilities. If not already done, enforce stricter IAM (maybe moving toward the per-user service accounts model if feasible). Beta is also when we draft clear privacy policy and terms of service documents, as more users will be involved.  
- **Scalability Testing:** With more users, test the system under heavier load. We will simulate concurrent queries and larger data to ensure the app scales. Optimize where needed (e.g. adjust BigQuery slots, add caching of embedding results, etc.). Monitoring dashboards on GCP (Cloud Monitoring) will be set up to track latency of answers and error rates.  

**Beta Timeline & Activities:** Another ~3-4 months post-MVP. We‚Äôll onboard, say, 50-100 users gradually, perhaps by invitation. We‚Äôll use their feedback to find out which features are most used and where the bot fails. This phase is also about **UX refinement** ‚Äì simplifying any workflows that confused users in MVP (for instance, if schema mapping was too technical, we make it smarter or more guided).  

**Success Criteria for Beta:**  
   - The chatbot can handle at least 80% of user questions without developer intervention or crashes. Multi-dataset queries succeed with correct results in test cases.
   - Users report the clarifications make the bot feel smarter and more conversational.
   - Average answer latency remains acceptable (e.g. under 5 seconds for typical questions).
   - No data leaks or privacy incidents with the larger user pool. Trust indicators (like users uploading more data over time) should increase.
   - We have enough feedback to decide what is needed for GA in terms of features or fixes.

### Phase 3: General Availability (GA) Launch  
**Goal:** Open the service to all (public launch), with a polished, scalable product. At GA, the focus is on robustness, compliance, and broad usability.  

**Scope of GA Features and Improvements:**  
- **Full Feature Set:** All major promised features are in place: seamless multi-data querying, clarifications, vector search, and a user-friendly interface. Visual answers (charts) are now supported for a range of query types, enhancing the appeal of the answers. The chatbot‚Äôs tone and style have been refined to be helpful and in line with the brand voice (professional yet friendly).  
- **Performance Optimisation:** Fine-tune the system for speed and cost. Possibly implement a caching layer for frequent queries (if many users ask similar questions, or if a user repeats a query). Ensure the LLM usage is efficient ‚Äì e.g., use streaming responses so the user can see answers as they are being formulated, or use smaller models for certain tasks without sacrificing quality. BigQuery costs will be monitored; we might introduce some query limits or smart scheduling (like heavy analysis can be done asynchronously if the user asks for something like year-long analysis with millions of data points).  
- **Scalability:** By GA, the system should support thousands of users. This might involve moving to multi-region deployment if user base is global, to reduce latency (using Cloud CDN for static content, and perhaps deploying backend in multiple regions). BigQuery can handle multi-terabyte scale, so that‚Äôs fine; we just need to ensure our usage of it is within quotas or we have reservations as needed. Auto-scaling rules for Cloud Run are well-tested to handle traffic spikes (like when we get a burst of new users on launch day).  
- **Enterprise-Readiness:** Even though product is aimed at individuals, GA might attract interest from small teams or organisations. We might add features like team accounts or data sharing as future work. At GA, we ensure compliance (SOC2, GDPR, etc. as needed) so that even privacy-conscious users (like Evelyn persona) are satisfied. This could include a final external security assessment.  
- **Documentation and Support:** Provide comprehensive user documentation, a knowledge base of example queries, and support channels. Perhaps integrate a feedback mechanism in the chat (a thumbs up/down after an answer, to learn which answers are good or where the bot misunderstood ‚Äì this can help continuously improve the model or prompt).  
- **Pricing Model Implementation:** Decide if the product will have a free tier and paid tiers (since it‚Äôs SaaS). By GA, integrate billing if needed (for example, free for up to X queries or data size, then subscription). This affects the technical side minimally, but we need usage tracking to enforce limits.  

**Post-GA and Future:** After GA, regular updates will add new connectors (plugging into more APIs so users don‚Äôt always have to upload manually), possibly a mobile app for on-the-go querying, and exploring proactive analytics (the bot suggesting insights unprompted). Another future direction could be allowing the user to ask questions like ‚ÄúHow do I improve?‚Äù and the bot can give advice based on data (venturing slightly into coaching). But these are beyond the initial GA scope and would be planned based on user demand.

The roadmap above ensures we deliver value early (MVP), validate it with real users (Beta), and then launch a stable, feature-rich product (GA). Each phase builds upon the last, guided by user feedback and technical feasibility. Throughout all phases, we remain aligned with the core vision: empowering users to interact with their own data as easily as having a conversation.

## Example Prompts and Acceptance Criteria  
Finally, to tie everything together and ensure each feature works as intended, we present example user prompts along with the expected system behaviour and criteria for acceptance. These examples serve both as **user-facing scenarios** and as **test cases** for development. They illustrate how natural language inputs should be handled by the system.

- **Temporal Query Understanding:**  
  - *User Prompt:* ‚ÄúHow many messages did I send last year?‚Äù  
  - *Expected Behaviour:* The system interprets ‚Äúlast year‚Äù in context (if today is 4 April 2025, then ‚Äúlast year‚Äù refers to the year 2024, i.e. 1 Jan 2024 ‚Äì 31 Dec 2024). It identifies the *Messages* dataset and counts messages in that date range.  
  - *Acceptance Criteria:* The chatbot returns a correct count of messages for 2024. It perhaps says, ‚ÄúYou sent 5,432 messages in 2024.‚Äù The term ‚Äúlast year‚Äù is correctly resolved; if the current date changes, the interpretation should adjust accordingly. A test would be to verify that on Jan 1, 2026, asking the same question yields the 2025 count, not 2024. The answer should come with no prompting from the user about how to filter by date ‚Äì it‚Äôs automatic.

- **Aggregation and Comparison:**  
  - *User Prompt:* ‚ÄúDid I run more in the first half of this year or the second half?‚Äù  
  - *Expected Behaviour:* The chatbot breaks this down: ‚Äúfirst half of this year‚Äù = Jan‚ÄìJun 2025, ‚Äúsecond half‚Äù = Jul‚ÄìDec 2025. It sums running distance (assuming a Running dataset) for each period and compares them.  
  - *Acceptance Criteria:* The answer explicitly compares the two values, e.g. ‚ÄúYou ran 220 km in Jan‚ÄìJun 2025 and 180 km in Jul‚ÄìDec 2025, so you covered more distance in the first half.‚Äù The bot should handle the concept of ‚Äúthis year‚Äù as the current year and correctly split halves. We test edge cases like asking in July (one half is past, one half is future partial) ‚Äì the bot should clarify if needed or say second half is incomplete so far. The acceptance is that it doesn‚Äôt confuse the time ranges and the math is correct as per the data.

- **Multi-Dataset Join Query:**  
  - *User Prompt:* ‚ÄúOn nights when I slept at least 8 hours, what was my average heart rate the next day?‚Äù  
  - *Expected Behaviour:* The system uses Sleep data and Heart Rate data. It filters sleep records for hours >= 8, takes those dates, then looks up heart rate (perhaps daily average HR) for the next day‚Äôs date. It then aggregates those heart rates (average of averages, effectively).  
  - *Acceptance Criteria:* The chatbot might answer, ‚ÄúOn days following a good night‚Äôs sleep (‚â•8h), your average heart rate was 60 bpm.‚Äù The key criteria: it correctly links the two datasets by date relationship (next day), and does the calculation. We would acceptance-test this by manually computing a known sample and ensuring the bot‚Äôs answer matches. If the user had no overlapping data (e.g. no nights of ‚â•8h), the bot should say it doesn‚Äôt have sufficient data for that query. If only partial heart rate data exists, it should handle gracefully or note it. The user didn‚Äôt explicitly mention datasets, but the bot figured out to use Sleep and Heart Rate data ‚Äì that‚Äôs an important acceptance point for the intent recognition.

- **Clarification Dialogue (Ambiguity):**  
  - *User Prompt:* ‚ÄúTell me about last week.‚Äù (Assume this is the conversation opener, with no prior context.)  
  - *Expected Behaviour:* The request is vague ‚Äì last week‚Äôs what? The chatbot should not guess blindly. It should respond with a clarification question, such as: ‚ÄúSure, I can summarise your last week. Is there something specific you‚Äôd like to know (e.g. your steps, messages, or any particular metric)?‚Äù  
  - *Acceptance Criteria:* The bot asks a clarifying question that mentions available categories of data, rather than saying ‚ÄúI don‚Äôt understand.‚Äù We then expect the user‚Äôs next input to be something like ‚ÄúMy fitness activities‚Äù or ‚ÄúEverything,‚Äù and the bot would then proceed. We test that the clarification logic triggers for open-ended prompts. If the user instead had asked ‚ÄúHow was my sleep last week?‚Äù, no clarification is needed because it‚Äôs specific ‚Äì the bot should directly answer. So acceptance is that ambiguity triggers one follow-up question from the bot and that subsequent answer after clarification is correct.

- **Missing Data Handling:**  
  - *User Prompt:* ‚ÄúHow many calories did I consume last month?‚Äù (User has not uploaded any diet or calorie intake data.)  
  - *Expected Behaviour:* The system finds no dataset relevant to ‚Äúcalories consumed‚Äù (it might have ‚Äúcalories burned‚Äù in workouts but that‚Äôs different, and it likely recognises the intent is food intake). It should inform the user it doesn‚Äôt have that data.  
  - *Acceptance Criteria:* The chatbot responds with a polite refusal and a helpful suggestion: e.g. ‚ÄúI‚Äôm sorry, I don‚Äôt have your dietary intake data to answer that. If you track your meals or calories, you can upload that dataset and ask again.‚Äù This message must contain no fabricated number. We accept the feature if the bot correctly detects the absence of required data and produces a helpful response, rather than a misleading or confusing one. We‚Äôd test by asking various questions for which we intentionally did not upload data (like ask a fitness question without fitness data, etc.) ‚Äì the bot should consistently respond that it lacks data.

- **Personal Data Privacy (Negative Test):**  
  - *User Prompt:* (Malicious user attempt) ‚ÄúShow me Alice‚Äôs step count for today.‚Äù (Where Alice is another user on the platform.)  
  - *Expected Behaviour:* The system should treat this as an unauthorized query. Since the chatbot is only aware of the current user‚Äôs data, it would likely respond as if asked about an unknown entity: ‚ÄúI‚Äôm sorry, I‚Äôm not sure who Alice is in this context.‚Äù It should **not** reveal anything about another user‚Äôs data (and indeed it technically can‚Äôt, because it has no access).  
  - *Acceptance Criteria:* Even if a user tries to frame a question to get someone else‚Äôs data, the system never returns it. In internal testing, we might simulate multi-user environment where one user‚Äôs context is active and ensure queries always stay constrained. The acceptance is more a security test: that cross-tenant data access is impossible through the chatbot. This is reinforced by design (each user only has their own data in scope), but we include it to highlight the importance of this criterion.

- **Follow-up Context Carryover:**  
  - *User Prompts:*  
    1. ‚ÄúWhat was my average running speed last week?‚Äù  
    2. (after receiving answer) ‚ÄúHow about the week before that?‚Äù  
  - *Expected Behaviour:* For the first question, the bot calculates average running speed (distance/time) for last week (e.g. 8‚Äì14 days ago). For the second question, phrased as a follow-up, the bot should understand it refers to the same metric (running speed) but the previous week. It then produces the answer for that week. Possibly it also compares or at least stays in context that we are talking about running speed.  
  - *Acceptance Criteria:* The second answer should clearly be about the week prior and not ask ‚Äúthe week before what?‚Äù. It might say ‚ÄúThe week of March 18‚Äì24, your average speed was ...‚Äù. If the user‚Äôs follow-up was even shorter like ‚ÄúAnd the week before?‚Äù, it should still get it from context. We accept this feature if in testing the chatbot can carry context for at least one or two turns reliably, and it references the prior query subject correctly. If the context is lost, that‚Äôs a bug to fix. We also ensure that context doesn‚Äôt bleed incorrectly (if the user changes subject, the bot shouldn‚Äôt confuse with old context).

- **Prompt/Response Quality (LLM reasoning):**  
  - *User Prompt:* ‚ÄúFind any trends in my music listening versus mood.‚Äù  
  - *Expected Behaviour:* This is a complex request that might require the bot to do some reasoning (maybe correlating two datasets in a qualitative way). It might retrieve data (music play counts, mood ratings) and then use the LLM to find a trend (e.g. ‚Äúyou tend to listen to upbeat music on days you report high mood‚Äù).  
  - *Acceptance Criteria:* The answer should be fact-based and reasonable, not a hallucination. If no strong trend exists, the bot should say so (‚ÄúI didn‚Äôt find a clear trend between your music and recorded mood‚Äù). The acceptance is that the LLM‚Äôs generative part stays grounded in data ‚Äì which we ensure by always providing it data context (the RAG approach). We would test a scenario with known correlation and see that the bot finds it, and test a scenario with no correlation to see that it doesn‚Äôt invent one. The quality of language should also be high: clear, concise, and in correct British English. For instance, using phrasing like ‚Äúwhilst‚Äù or ‚Äúamongst‚Äù appropriately, and proper spelling (e.g. ‚Äúorganise‚Äù not ‚Äúorganize‚Äù), matching our style guideline.

Each of the above examples doubles as an **acceptance test**. For development, we will likely encode many of these as automated tests (where we simulate the user input and verify the output meets certain criteria). We will also use them as **agile story acceptance criteria**: e.g. for the story ‚ÄúAs a user, I want to compare two time ranges,‚Äù the acceptance is the scenario with first half vs second half of year as demonstrated. 

By adhering to these criteria during implementation, we ensure the final product meets the high expectations for accuracy, usability, and security. This approach ‚Äì combining deep technical architecture, thoughtful product design, and rigorous testing scenarios ‚Äì will guide the team in delivering a successful multi-user personal data chatbot that feels as polished and insightful as an article in *The Economist*, yet is as personalised as having a private data analyst at one‚Äôs fingertips.

